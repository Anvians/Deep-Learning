{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anvians/Deep-Learning/blob/main/FakeNewsDetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install datasets"
      ],
      "metadata": {
        "id": "UZDFwboNpo4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "TfLwe6ceoXxc"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "from datasets import load_dataset\n",
        "import torch\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "9pbTU8KpoZvg"
      },
      "outputs": [],
      "source": [
        "dataset = load_dataset(\"liar\",trust_remote_code=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "2a2aNe57odDK"
      },
      "outputs": [],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Tokenize the dataset\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples['statement'], padding=\"max_length\", truncation=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "yz_8PXHNoe0s"
      },
      "outputs": [],
      "source": [
        "train_dataset = dataset['train'].map(tokenize_function, batched=True, remove_columns=[\"statement\"])\n",
        "test_dataset = dataset['test'].map(tokenize_function, batched=True, remove_columns=[\"statement\"])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTkSg9trs1-v",
        "outputId": "aa4b6e37-6b5d-48a8-ab20-bf63dde45053"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': (10269, 14), 'test': (1283, 14), 'validation': (1284, 14)}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9iv5zJFtCD1",
        "outputId": "5a6b435e-62c7-4a29-fef6-1e3980b22640"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30522"
            ]
          },
          "metadata": {},
          "execution_count": 22
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30522"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.vocab_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPfUqHr3uuYq",
        "outputId": "0b53943b-108f-4eaa-b194-3d8eebe07b30"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30522"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "493wyLoo7sRO",
        "outputId": "26f38e31-bc47-46ec-9dc1-674ba4c651b7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10269"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "dataset['train']['statement'].__len__()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7TNJKAwxTBo"
      },
      "source": [
        "### Building my own Transformer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "6ygLAe32Afaf"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Embedding Layer**"
      ],
      "metadata": {
        "id": "SDKoU-AZxi4m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_layer = nn.Embedding(num_embeddings=tokenizer.vocab_size, embedding_dim=768)"
      ],
      "metadata": {
        "id": "tWz9ild7hPzQ"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idss in train_dataset['input_ids']:\n",
        "  input_ids = torch.tensor(idss).unsqueeze(0)\n",
        "  input_embedding = embedding_layer(input_ids)\n",
        "\n",
        "input_embedding.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0YVe3VgsPh8",
        "outputId": "81c3c364-85ef-4e0b-bc0b-796b78877c83"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 512, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Positional Encoding**"
      ],
      "metadata": {
        "id": "87GXnowSsRcc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Positional_encoding(nn.Module):\n",
        "  def __init__(self, embedding_dim, max_seq_length):\n",
        "    super().__init__()\n",
        "    self.encoding = torch.zeros(max_seq_length, embedding_dim)\n",
        "    position = torch.arange(0, max_seq_length, dtype=torch.float).unsqueeze(1).float()\n",
        "    # div_term = torch.tensor([(10000 ** (2 * i)) / embedding_dim for i in range(embedding_dim)], dtype=torch.float)\n",
        "    div_term = torch.exp(torch.arange(0, embedding_dim, 2).float() * (-torch.log(torch.tensor(10000.0)) / embedding_dim))\n",
        "    self.encoding[:, 0::2] = torch.sin(position/div_term)\n",
        "    self.encoding[:, 1::2] = torch.cos(position/div_term)\n",
        "    self.encoding = self.encoding.unsqueeze(0)\n",
        "\n",
        "  def forward(self, x):\n",
        "    seq_length = x.size(1)\n",
        "    return x + self.encoding[:, :seq_length, :].to(x.device)\n",
        "\n"
      ],
      "metadata": {
        "id": "l5SCVd3Xx3dc"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positional_encoding = Positional_encoding(embedding_dim = 768, max_seq_length = 512)\n",
        "input_embedding_with_position = positional_encoding(input_embedding)\n",
        "input_embedding_with_position.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JuYb2Y2fArA9",
        "outputId": "a1921ace-0796-4fc4-da82-6711c4ed74b6"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 512, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Multihead Attention**"
      ],
      "metadata": {
        "id": "rB-07W8KBl29"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Multihead_attention(nn.Module):\n",
        "  def __init__(self, embedding_dim, num_heads):\n",
        "    super().__init__()\n",
        "    self.num_heads = num_heads\n",
        "    self.head_dim = embedding_dim // num_heads\n",
        "\n",
        "\n",
        "    self.q_layer = nn.Linear(embedding_dim, embedding_dim)\n",
        "    self.k_layer = nn.Linear(embedding_dim, embedding_dim)\n",
        "    self.v_layer = nn.Linear(embedding_dim, embedding_dim)\n",
        "\n",
        "    self.output_layer = nn.Linear(embedding_dim, embedding_dim)\n",
        "\n",
        "  def forward(self, x):\n",
        "    batch_size, seq_length, embedding_dim = x.size()\n",
        "    Q = self.q_layer(x)\n",
        "    K = self.k_layer(x)\n",
        "    V = self.v_layer(x)"
      ],
      "metadata": {
        "id": "aNFhjCxYCfRD"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNdIWDPz/NdFROKqAg49KqP",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}